# Unified Scraper Usage Guide

## ğŸ¯ Overview

The `unified_scraper.py` is a single file that:
1. Runs your existing `linkdin_scrapper.py` 
2. Runs your existing `resume_parser/parse_resume.ts`
3. Combines the results into a single JSON file
4. Stores it in the `lda_logs/` folder inside the `lda` directory

## ğŸ“ File Structure

```
Brain/lda/
â”œâ”€â”€ unified_scraper.py          # Single file that does everything
â”œâ”€â”€ lda_logs/                   # Combined data storage
â”‚   â””â”€â”€ combined_candidate_data_Name_TIMESTAMP.json
â”œâ”€â”€ knowledge_db.py             # Enhanced to load combined data
â””â”€â”€ main.py                     # Updated to use combined data
```

## ğŸš€ Usage Examples

### LinkedIn + Resume (Complete)
```bash
cd Brain/lda
export LINKEDIN_EMAIL="your_email@example.com"
export LINKEDIN_PASSW="your_password"

python unified_scraper.py \
  --linkedin-url "https://linkedin.com/in/username" \
  --resume-pdf "../../path/to/resume.pdf"
```

### LinkedIn Only
```bash
cd Brain/lda
python unified_scraper.py \
  --linkedin-url "https://linkedin.com/in/username" \
  --linkedin-email "email@example.com" \
  --linkedin-password "password"
```

### Resume Only
```bash
cd Brain/lda
python unified_scraper.py --resume-pdf "../../path/to/resume.pdf"
```

### With Custom Candidate Name
```bash
cd Brain/lda
python unified_scraper.py \
  --linkedin-url "https://linkedin.com/in/johndoe" \
  --candidate-name "John Doe"
```

## ğŸ“Š Output Format

The unified scraper creates a combined JSON file:

```json
{
  "timestamp": "2025-01-27T10:30:00",
  "candidate_name": "Vatsal Jain",
  "data_sources": {
    "linkedin": true,
    "resume": true
  },
  "linkedin_data": {
    "name": "Vatsal Jain",
    "about": "...",
    "experiences": [...],
    "educations": [...],
    "skills": [...],
    "projects": [...],
    "licenses": [...],
    "honors": [...]
  },
  "resume_data": {
    "sections": {
      "HEADER": ["VATSAL JAIN"],
      "IIT COURSE": [...],
      "INTERNSHIPS": [...],
      "PROJECTS": [...],
      "TECHNICAL SKILLS": [...]
    }
  },
  "metadata": {
    "scraper_version": "unified_scraper_v1.0.0",
    "linkedin_entries": 60,
    "resume_entries": 83,
    "total_entries": 143
  }
}
```

## ğŸ”§ Integration with Interview System

The interview system automatically uses the combined data:

1. **Run unified scraper** to collect fresh data:
   ```bash
   cd Brain/lda
   python unified_scraper.py --linkedin-url "https://linkedin.com/in/candidate"
   ```

2. **Run interview system** - it automatically loads the latest combined data:
   ```bash
   cd Brain/lda
   python main.py
   ```

## ğŸ“‹ What Gets Extracted

### LinkedIn Data
- âœ… Personal info (name, about)
- âœ… Work experiences (5+ positions)
- âœ… Key achievements (15+ accomplishments)
- âœ… Education (degrees, GPAs)
- âœ… Skills (20+ technical skills)
- âœ… Projects (9+ projects)
- âœ… Certifications (3+ certs)
- âœ… Honors and awards

### Resume Data
- âœ… Personal info (name)
- âœ… Education (degrees, institutions, GPAs)
- âœ… Internships and positions
- âœ… Technical skills (60+ skills)
- âœ… Projects (8+ projects)
- âœ… Academic achievements
- âœ… Course details

### Total: 143+ knowledge entries!

## ğŸ”„ How It Works

1. **LinkedIn Scraping**: 
   - Modifies your existing `linkdin_scrapper.py` to use the provided URL
   - Runs Selenium automation
   - Saves to `logs/person_*.json`

2. **Resume Parsing**:
   - Runs your existing `resume_parser/parse_resume.ts`
   - Processes PDF with TypeScript
   - Saves to `logs/resume_*.json`

3. **Data Combination**:
   - Loads both JSON files
   - Combines into unified format
   - Saves to `lda_logs/combined_candidate_data_*.json`

4. **Knowledge Base Integration**:
   - Interview system auto-loads from `lda_logs/`
   - Extracts 143+ entries for comprehensive fact-checking
   - Enables accurate lie detection and informed questioning

## ğŸ‰ Benefits

- âœ… **Single command** runs both scrapers
- âœ… **Combined output** in one JSON file
- âœ… **Organized storage** in dedicated `lda_logs/` folder
- âœ… **Automatic integration** with interview system
- âœ… **Comprehensive data** extraction (143+ entries vs 1-2 before)
- âœ… **Uses existing tools** - no rewriting needed
- âœ… **Backwards compatible** - still works with old separate files

## âš¡ Quick Start

```bash
# 1. Set LinkedIn credentials
export LINKEDIN_EMAIL="your_email@example.com"
export LINKEDIN_PASSW="your_password"

# 2. Run unified scraper
cd Brain/lda
python unified_scraper.py \
  --linkedin-url "https://linkedin.com/in/candidate" \
  --resume-pdf "../../candidate_resume.pdf"

# 3. Run interview (automatically uses combined data)
python main.py
```

The interview system will now have comprehensive candidate information for accurate lie detection and informed questioning! ğŸ¯
